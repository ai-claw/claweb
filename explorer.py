"""
æ™ºèƒ½æ¢ç´¢æ¨¡å— - è‡ªä¸»æ¢ç´¢ç½‘ç«™å¹¶å­¦ä¹ 
"""

import asyncio
import json
import os
import re
import uuid
from datetime import datetime
from typing import Dict, List, Optional, Tuple, Set
from urllib.parse import urlparse, urljoin

from playwright.async_api import Page

from config import Config
from browser import BrowserManager
from page_tagger import PageTagger
from llm_client import VisionLLMClient
from database import DatabaseInterface, create_database
from models import (
    Site, Page as PageModel, Element, Action, ExplorationLog,
    PageType, ElementType, ActionType
)


class PageAnalyzer:
    """é¡µé¢åˆ†æå™¨ - ä½¿ç”¨ LLM åˆ†æé¡µé¢è¯­ä¹‰"""
    
    ANALYZE_PAGE_PROMPT = """åˆ†æè¿™ä¸ªç½‘é¡µæˆªå›¾ï¼Œè¿”å›ä»¥ä¸‹ JSON æ ¼å¼çš„ä¿¡æ¯ï¼š

{
    "page_type": "é¡µé¢ç±»å‹ï¼Œå¯é€‰: login/home/list/detail/form/search/settings/error/auth/dashboard/unknown",
    "page_description": "ä¸€å¥è¯æè¿°è¿™ä¸ªé¡µé¢çš„åŠŸèƒ½",
    "key_features": ["é¡µé¢çš„å…³é”®ç‰¹å¾ï¼Œå¦‚ï¼šæœ‰æœç´¢æ¡†ã€æœ‰å¯¼èˆªæ ã€æœ‰è¡¨æ ¼ç­‰"],
    "has_sidebar_nav": true/false,
    "sidebar_nav_items": ["ä¾§è¾¹æ å¯¼èˆªèœå•é¡¹åç§°åˆ—è¡¨ï¼Œå¦‚ï¼šæ•°æ®æ€»è§ˆã€ä»»åŠ¡ç®¡ç†ç­‰"],
    "important_elements": [
        {
            "semantic_name": "å…ƒç´ çš„è¯­ä¹‰åç§°ï¼Œå¦‚ï¼šç™»å½•æŒ‰é’®ã€ç”¨æˆ·åè¾“å…¥æ¡†",
            "element_type": "button/link/input/select/checkbox/nav_item/other",
            "text_content": "å…ƒç´ æ˜¾ç¤ºçš„æ–‡æœ¬",
            "position": "ä½ç½®æè¿°ï¼Œå¦‚ï¼šé¡¶éƒ¨å¯¼èˆªæ ã€é¡µé¢ä¸­å¤®ã€å·¦ä¾§è¾¹æ ",
            "importance": 1-10çš„é‡è¦æ€§è¯„åˆ†,
            "is_nav_menu": true/false,
            "action_suggestion": "å»ºè®®çš„æ“ä½œï¼Œå¦‚ï¼šç‚¹å‡»è¿›å…¥è¯¦æƒ…ã€è¾“å…¥æœç´¢å…³é”®è¯"
        }
    ],
    "suggested_explorations": ["å»ºè®®æ¢ç´¢çš„æ“ä½œï¼Œä¼˜å…ˆçº§ä»é«˜åˆ°ä½"]
}

æ³¨æ„ï¼š
1. important_elements åªåŒ…å«å€¼å¾—äº¤äº’çš„å…ƒç´ ï¼ˆæŒ‰é’®ã€é“¾æ¥ã€è¾“å…¥æ¡†ç­‰ï¼‰
2. å¿½ç•¥çº¯è£…é¥°æ€§å…ƒç´ 
3. å¦‚æœçœ‹åˆ°ç™»å½•/éªŒè¯ç é¡µé¢ï¼Œpage_type è®¾ä¸º auth
4. å¦‚æœæœ‰ä¾§è¾¹æ å¯¼èˆªèœå•ï¼Œhas_sidebar_nav è®¾ä¸º trueï¼Œå¹¶åˆ—å‡ºæ‰€æœ‰èœå•é¡¹
5. å¯¼èˆªèœå•é¡¹çš„ is_nav_menu è®¾ä¸º trueï¼Œimportance è®¾ä¸º 9-10
6. suggested_explorations åº”è¯¥ä¼˜å…ˆåŒ…å«å¯¼èˆªèœå•çš„æ¢ç´¢"""

    ANALYZE_ELEMENTS_PROMPT = """è¿™æ˜¯ç½‘é¡µæˆªå›¾ï¼Œé¡µé¢ä¸Šçš„å¯äº¤äº’å…ƒç´ å·²è¢«æ ‡è®°ï¼š
- [#ID]ï¼šè¾“å…¥æ¡†
- [@ID]ï¼šé“¾æ¥
- [$ID]ï¼šæŒ‰é’®ç­‰å…¶ä»–å¯äº¤äº’å…ƒç´ 

å½“å‰é¡µé¢æè¿°ï¼š{page_description}

è¯·åˆ†ææ ‡è®°çš„å…ƒç´ ï¼Œè¿”å› JSON æ ¼å¼ï¼š
{{
    "elements": [
        {{
            "tag_id": å…ƒç´ æ ‡ç­¾IDï¼ˆçº¯æ•°å­—ï¼‰,
            "semantic_name": "è¯­ä¹‰åç§°",
            "element_type": "button/link/input/select/nav_item/other",
            "text_or_hint": "å…ƒç´ æ–‡æœ¬æˆ–æç¤º",
            "importance": 1-10,
            "explore_priority": 1-10,
            "is_nav_menu": true/false,
            "is_crud_action": true/false,
            "crud_type": "create/read/update/delete/none",
            "action_suggestion": "å»ºè®®æ“ä½œ"
        }}
    ]
}}

é‡è¦è§„åˆ™ï¼š
1. ä¾§è¾¹æ å¯¼èˆªèœå•é¡¹ï¼ˆå¦‚ï¼šæ•°æ®æ€»è§ˆã€ä»»åŠ¡ç®¡ç†ã€æµ‹è¯•ç”¨ä¾‹ç­‰ï¼‰çš„ is_nav_menu è®¾ä¸º trueï¼Œexplore_priority è®¾ä¸º 9-10
2. é¡¶éƒ¨å¯¼èˆªèœå•é¡¹ä¹Ÿæ˜¯é«˜ä¼˜å…ˆçº§
3. **CRUD æ“ä½œæŒ‰é’®å¿…é¡»è¯†åˆ«**ï¼š
   - æ–°å»º/åˆ›å»º/æ·»åŠ /æ–°å¢ -> crud_type="create", is_crud_action=true, explore_priority=9
   - æŸ¥çœ‹/è¯¦æƒ…/æŸ¥è¯¢/æœç´¢ -> crud_type="read", is_crud_action=true, explore_priority=8
   - ç¼–è¾‘/ä¿®æ”¹/æ›´æ–° -> crud_type="update", is_crud_action=true, explore_priority=8
   - åˆ é™¤/ç§»é™¤/ä½œåºŸ -> crud_type="delete", is_crud_action=true, explore_priority=7
4. åˆ—è¡¨é¡µä¸­çš„æ“ä½œåˆ—æŒ‰é’®ï¼ˆç¼–è¾‘ã€åˆ é™¤ã€æŸ¥çœ‹è¯¦æƒ…ç­‰ï¼‰å¿…é¡»æ ‡è®°ä¸ºé«˜ä¼˜å…ˆçº§
5. è¡¨æ ¼è¡Œå†…çš„æ“ä½œé“¾æ¥ä¹Ÿéœ€è¦è¯†åˆ«
6. æ™®é€šæ— æ“ä½œæ„ä¹‰çš„æŒ‰é’®å’Œé“¾æ¥çš„ explore_priority è®¾ä¸º 3-5
7. åªè¿”å›å€¼å¾—æ¢ç´¢çš„å…ƒç´ ï¼Œå¿½ç•¥çº¯è£…é¥°æ€§å…ƒç´ """

    def __init__(self, llm_client: VisionLLMClient):
        self.llm = llm_client
    
    async def analyze_page(self, screenshot: bytes) -> Dict:
        """åˆ†æé¡µé¢ï¼Œè¿”å›é¡µé¢è¯­ä¹‰ä¿¡æ¯"""
        try:
            response = await self.llm.analyze_with_vision(
                screenshot,
                self.ANALYZE_PAGE_PROMPT
            )
            
            print(f"    [DEBUG] LLM analyze_page å“åº”é•¿åº¦: {len(response) if response else 0}")
            if response:
                print(f"    [DEBUG] LLM å“åº”å‰200å­—ç¬¦: {response[:200]}...")
            
            # è§£æ JSON å“åº”
            if response:
                json_match = re.search(r'\{[\s\S]*\}', response)
                if json_match:
                    return json.loads(json_match.group())
                else:
                    print(f"    [DEBUG] æ— æ³•ä»å“åº”ä¸­æå– JSON")
        except json.JSONDecodeError as e:
            print(f"    [DEBUG] JSON è§£æå¤±è´¥: {e}")
        except Exception as e:
            print(f"    åˆ†æé¡µé¢å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
        
        # è¿”å›é»˜è®¤å€¼
        return {
            "page_type": "unknown",
            "page_description": "æ— æ³•åˆ†æçš„é¡µé¢",
            "key_features": [],
            "has_sidebar_nav": False,
            "sidebar_nav_items": [],
            "important_elements": [],
            "suggested_explorations": []
        }
    
    async def analyze_elements(
        self, 
        screenshot: bytes, 
        page_description: str
    ) -> List[Dict]:
        """åˆ†ææ ‡è®°åçš„é¡µé¢å…ƒç´ """
        try:
            prompt = self.ANALYZE_ELEMENTS_PROMPT.format(page_description=page_description)
            response = await self.llm.analyze_with_vision(screenshot, prompt)
            
            print(f"    [DEBUG] LLM analyze_elements å“åº”é•¿åº¦: {len(response) if response else 0}")
            if response:
                print(f"    [DEBUG] LLM å“åº”å‰300å­—ç¬¦: {response[:300]}...")
            
            if response:
                json_match = re.search(r'\{[\s\S]*\}', response)
                if json_match:
                    data = json.loads(json_match.group())
                    elements = data.get("elements", [])
                    print(f"    [DEBUG] è§£æåˆ° {len(elements)} ä¸ªå…ƒç´ ")
                    return elements
                else:
                    print(f"    [DEBUG] æ— æ³•ä»å“åº”ä¸­æå– JSON")
        except json.JSONDecodeError as e:
            print(f"    [DEBUG] JSON è§£æå¤±è´¥: {e}")
        except Exception as e:
            print(f"    åˆ†æå…ƒç´ å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
        
        return []


class SiteExplorer:
    """ç½‘ç«™æ¢ç´¢å™¨ - æ™ºèƒ½æ¢ç´¢ç½‘ç«™å¹¶è®°å½•æ“ä½œ"""
    
    def __init__(self, config: Config, db: DatabaseInterface):
        self.config = config
        self.db = db
        self.browser_manager: Optional[BrowserManager] = None
        self.page_tagger = PageTagger()
        self.llm_client = VisionLLMClient(config.llm)
        self.page_analyzer = PageAnalyzer(self.llm_client)
        
        self.session_id = str(uuid.uuid4())[:8]
        self.current_site: Optional[Site] = None
        self.visited_urls: Set[str] = set()
        self.visited_items: Set[str] = set()  # å·²è®¿é—®çš„å¯¼èˆª/æ“ä½œé¡¹
        self.pending_items: List[Dict] = []   # å¾…æ¢ç´¢çš„é¡¹ç›®ï¼ˆå¯¼èˆªèœå• + CRUD æ“ä½œï¼‰
        self.exploration_depth = 0
        
        # ç¡®ä¿æˆªå›¾ç›®å½•å­˜åœ¨
        os.makedirs(config.exploration.screenshot_dir, exist_ok=True)
    
    async def start(self) -> None:
        """å¯åŠ¨æ¢ç´¢å™¨"""
        self.browser_manager = BrowserManager(self.config.browser)
        await self.browser_manager.start()
        self.db.connect()
    
    async def stop(self) -> None:
        """åœæ­¢æ¢ç´¢å™¨"""
        if self.browser_manager:
            await self.browser_manager.stop()
        self.db.close()
    
    async def explore_site(self, start_url: str, site_name: str = "") -> Site:
        """
        æ¢ç´¢æ•´ä¸ªç½‘ç«™ï¼ˆå¹¿åº¦ä¼˜å…ˆæ¢ç´¢ï¼šå¯¼èˆªèœå• -> é¡µé¢å†… CRUD æ“ä½œï¼‰
        
        Args:
            start_url: èµ·å§‹ URL
            site_name: ç½‘ç«™åç§°
            
        Returns:
            Site: ç½‘ç«™ä¿¡æ¯
        """
        # è§£æåŸŸå
        parsed = urlparse(start_url)
        domain = parsed.netloc
        
        # åˆ›å»ºæˆ–è·å–ç½‘ç«™è®°å½•
        self.current_site = self.db.get_or_create_site(domain, site_name)
        
        print(f"\n{'='*60}")
        print(f"ğŸŒ å¼€å§‹æ¢ç´¢ç½‘ç«™: {domain}")
        print(f"ğŸ“ ä¼šè¯ ID: {self.session_id}")
        print(f"{'='*60}\n")
        
        # å¯¼èˆªåˆ°èµ·å§‹é¡µ
        await self.browser_manager.goto(start_url)
        await asyncio.sleep(2)  # ç­‰å¾…é¡µé¢åŠ è½½
        
        # ç¬¬ä¸€æ­¥ï¼šåˆ†æé¦–é¡µï¼Œæ”¶é›†æ‰€æœ‰å¯¼èˆªèœå•å’Œæ“ä½œ
        print("ğŸ“ ç¬¬ä¸€é˜¶æ®µï¼šåˆ†æé¡µé¢ç»“æ„ï¼Œæ”¶é›†å¯¼èˆªèœå•å’Œ CRUD æ“ä½œ...")
        await self._analyze_and_collect_items()
        
        # ç¬¬äºŒæ­¥ï¼šä¾æ¬¡æ¢ç´¢æ¯ä¸ªé¡¹ç›®
        print(f"\nğŸ“ ç¬¬äºŒé˜¶æ®µï¼šæ¢ç´¢æ‰€æœ‰é¡¹ç›® (å…± {len(self.pending_items)} ä¸ªå¾…æ¢ç´¢)...")
        await self._explore_all_items()
        
        print(f"\n{'='*60}")
        print(f"âœ… æ¢ç´¢å®Œæˆ!")
        print(f"ğŸ“Š è®¿é—®é¡µé¢æ•°: {len(self.visited_urls)}")
        print(f"ğŸ“Š æ¢ç´¢é¡¹ç›®æ•°: {len(self.visited_items)}")
        print(f"{'='*60}\n")
        
        return self.current_site
    
    async def _analyze_and_collect_items(self) -> None:
        """åˆ†æå½“å‰é¡µé¢å¹¶æ”¶é›†å¯¼èˆªèœå•é¡¹å’Œ CRUD æ“ä½œ"""
        page = self.browser_manager.page
        current_url = page.url
        
        # è®°å½•å½“å‰é¡µé¢
        url_key = self._normalize_url(current_url)
        self.visited_urls.add(url_key)
        
        print(f"\nğŸ“„ åˆ†æé¡µé¢: {current_url[:80]}...")
        
        # æˆªå›¾åˆ†æ
        screenshot = await self.browser_manager.screenshot()
        page_info = await self.page_analyzer.analyze_page(screenshot)
        
        page_type_str = page_info.get("page_type", "unknown")
        print(f"   ç±»å‹: {page_type_str}")
        print(f"   æè¿°: {page_info.get('page_description', 'æœªçŸ¥')}")
        
        # æ£€æŸ¥ä¾§è¾¹æ å¯¼èˆª
        if page_info.get("has_sidebar_nav"):
            nav_items = page_info.get("sidebar_nav_items", [])
            print(f"   ğŸ§­ å‘ç°ä¾§è¾¹æ å¯¼èˆª: {nav_items}")
        
        # ä¿å­˜é¡µé¢ä¿¡æ¯
        title = await page.title()
        page_model = PageModel(
            site_id=self.current_site.id,
            url_pattern=url_key,
            title_pattern=title,
            page_type=PageType(page_type_str) if page_type_str in [e.value for e in PageType] else PageType.UNKNOWN,
            semantic_description=page_info.get("page_description", ""),
            key_features=json.dumps(page_info.get("key_features", []), ensure_ascii=False),
            sample_url=current_url,
            visit_count=1
        )
        page_model = self.db.save_page(page_model)
        
        # ä¿å­˜æˆªå›¾
        screenshot_path = os.path.join(
            self.config.exploration.screenshot_dir,
            f"{self.session_id}_{page_model.id}.png"
        )
        with open(screenshot_path, "wb") as f:
            f.write(screenshot)
        
        # æ ‡è®°é¡µé¢å…ƒç´ å¹¶åˆ†æ
        print("   ğŸ·ï¸ æ ‡è®°å¹¶åˆ†æé¡µé¢å…ƒç´ ...")
        tagged_screenshot, tag_to_xpath = await self.page_tagger.tag_page(page)
        
        print(f"   ğŸ“Š æ ‡è®°ç»“æœ: screenshot={len(tagged_screenshot) if tagged_screenshot else 0} bytes, xpath_count={len(tag_to_xpath) if tag_to_xpath else 0}")
        
        if tagged_screenshot and tag_to_xpath:
            elements_info = await self.page_analyzer.analyze_elements(
                tagged_screenshot,
                page_info.get("page_description", "")
            )
            
            print(f"   ğŸ“Š LLM è¿”å›å…ƒç´ æ•°: {len(elements_info)}")
            if elements_info:
                print(f"   ğŸ“Š ç¬¬ä¸€ä¸ªå…ƒç´ ç¤ºä¾‹: {elements_info[0]}")
                print(f"   ğŸ“Š tag_to_xpath é”®ç±»å‹ç¤ºä¾‹: {list(tag_to_xpath.keys())[:5]}")
            
            # æ”¶é›†å¯¼èˆªèœå•é¡¹å’Œ CRUD æ“ä½œ
            nav_count = 0
            crud_count = 0
            for elem_info in elements_info:
                tag_id = elem_info.get("tag_id")
                if tag_id is None:
                    continue
                
                semantic_name = elem_info.get("semantic_name", "")
                is_nav = elem_info.get("is_nav_menu", False)
                is_crud = elem_info.get("is_crud_action", False)
                crud_type = elem_info.get("crud_type", "none")
                priority = elem_info.get("explore_priority", 5)
                
                # tag_id å¯èƒ½æ˜¯ intï¼Œä½† tag_to_xpath çš„é”®æ˜¯ int
                xpath = tag_to_xpath.get(tag_id) or tag_to_xpath.get(str(tag_id)) or tag_to_xpath.get(int(tag_id) if isinstance(tag_id, str) else tag_id)
                
                # ä¿å­˜å…ƒç´ åˆ°æ•°æ®åº“
                elem_type_str = elem_info.get("element_type", "other")
                element = Element(
                    page_id=page_model.id,
                    element_type=ElementType(elem_type_str) if elem_type_str in [e.value for e in ElementType] else ElementType.OTHER,
                    semantic_name=semantic_name,
                    semantic_description=elem_info.get("action_suggestion", ""),
                    text_content=elem_info.get("text_or_hint", ""),
                    importance=elem_info.get("importance", 5),
                    css_selector_hint=str(xpath) if xpath else ""
                )
                element = self.db.save_element(element)
                
                # å¦‚æœæ˜¯å¯¼èˆªèœå•é¡¹æˆ– CRUD æ“ä½œï¼ŒåŠ å…¥å¾…æ¢ç´¢åˆ—è¡¨
                item_key = f"{page_model.id}:{semantic_name}"  # é¡µé¢+åç§°ä½œä¸ºå”¯ä¸€é”®
                should_explore = (is_nav or is_crud or priority >= 7) and xpath and item_key not in self.visited_items
                
                if should_explore:
                    item_type = "crud" if is_crud else ("nav" if is_nav else "action")
                    self.pending_items.append({
                        "name": semantic_name,
                        "xpath": xpath,
                        "priority": priority,
                        "element_id": element.id,
                        "source_page_id": page_model.id,
                        "source_url": current_url,
                        "item_type": item_type,
                        "crud_type": crud_type,
                        "text": elem_info.get("text_or_hint", "")
                    })
                    
                    if is_nav:
                        nav_count += 1
                        print(f"      ğŸ§­ å¯¼èˆªé¡¹: {semantic_name} (ä¼˜å…ˆçº§: {priority})")
                    elif is_crud:
                        crud_count += 1
                        print(f"      ğŸ”§ CRUDæ“ä½œ [{crud_type}]: {semantic_name} (ä¼˜å…ˆçº§: {priority})")
                    else:
                        print(f"      ğŸ“Œ æ“ä½œé¡¹: {semantic_name} (ä¼˜å…ˆçº§: {priority})")
            
            if nav_count > 0 or crud_count > 0:
                print(f"   ğŸ“Š æ”¶é›†: {nav_count} ä¸ªå¯¼èˆªé¡¹, {crud_count} ä¸ª CRUD æ“ä½œ")
            
            # æŒ‰ä¼˜å…ˆçº§æ’åºï¼ˆå¯¼èˆªä¼˜å…ˆï¼Œç„¶å CRUDï¼‰
            self.pending_items.sort(key=lambda x: (
                10 if x["item_type"] == "nav" else 
                9 if x["crud_type"] == "create" else
                8 if x["crud_type"] in ("read", "update") else
                7 if x["crud_type"] == "delete" else
                x["priority"]
            ), reverse=True)
        
        # æ¸…ç†æ ‡ç­¾
        await self.page_tagger.cleanup(page)
    
    async def _explore_all_items(self) -> None:
        """æ¢ç´¢æ‰€æœ‰æ”¶é›†åˆ°çš„é¡¹ç›®ï¼ˆå¯¼èˆªèœå• + CRUD æ“ä½œï¼‰"""
        explored_count = 0
        max_items = self.config.exploration.max_pages * 3  # å¢åŠ æ¢ç´¢ä¸Šé™
        
        while self.pending_items and explored_count < max_items:
            item = self.pending_items.pop(0)
            item_name = item["name"]
            item_key = f"{item['source_page_id']}:{item_name}"
            
            if item_key in self.visited_items:
                continue
            
            self.visited_items.add(item_key)
            explored_count += 1
            
            item_type_icon = {
                "nav": "ğŸ§­",
                "crud": "ğŸ”§",
                "action": "ğŸ“Œ"
            }.get(item["item_type"], "ğŸ“Œ")
            
            print(f"\n{'â”€'*50}")
            print(f"{item_type_icon} [{explored_count}/{max_items}] æ¢ç´¢: {item_name}")
            if item["crud_type"] != "none":
                print(f"   ç±»å‹: {item['crud_type'].upper()}")
            print(f"{'â”€'*50}")
            
            # é¦–å…ˆç¡®ä¿åœ¨æ­£ç¡®çš„é¡µé¢ä¸Š
            await self._ensure_on_source_page(item)
            
            # ç‚¹å‡»é¡¹ç›®
            success = await self._click_item(item)
            
            if success:
                await asyncio.sleep(2)  # ç­‰å¾…é¡µé¢åŠ è½½æˆ–å¼¹çª—å‡ºç°
                
                # åˆ†ææ–°é¡µé¢/å¼¹çª—å¹¶æ”¶é›†æ›´å¤šé¡¹ç›®
                await self._analyze_after_click(item)
    
    async def _ensure_on_source_page(self, item: Dict) -> None:
        """ç¡®ä¿å½“å‰åœ¨æºé¡µé¢ä¸Š"""
        page = self.browser_manager.page
        source_url = item.get("source_url", "")
        current_url = page.url
        
        # å¦‚æœä¸åœ¨æºé¡µé¢ï¼Œå¯¼èˆªå›å»
        if source_url and self._normalize_url(current_url) != self._normalize_url(source_url):
            print(f"   ğŸ“ è¿”å›æºé¡µé¢: {source_url[:50]}...")
            await self.browser_manager.goto(source_url)
            await asyncio.sleep(2)
    
    async def _click_item(self, item: Dict) -> bool:
        """ç‚¹å‡»é¡¹ç›®ï¼ˆå¯¼èˆªèœå•æˆ– CRUD æŒ‰é’®ï¼‰"""
        page = self.browser_manager.page
        xpath = item["xpath"]
        
        try:
            # å…ˆæ¸…ç†ä¹‹å‰çš„æ ‡ç­¾
            await self.page_tagger.cleanup(page)
            
            # å°è¯•ç‚¹å‡»
            elem = page.locator(f"xpath={xpath}").first
            
            # æ£€æŸ¥å…ƒç´ æ˜¯å¦å­˜åœ¨ä¸”å¯è§
            try:
                visible = await elem.is_visible(timeout=3000)
            except Exception:
                visible = False
            
            if not visible:
                print(f"   âš ï¸ å…ƒç´ ä¸å¯è§ï¼Œå°è¯•é‡æ–°å®šä½...")
                # å°è¯•é€šè¿‡æ–‡æœ¬æŸ¥æ‰¾
                text = item.get("text") or item["name"]
                elem = page.get_by_text(text, exact=False).first
            
            await elem.click(timeout=5000)
            print(f"   âœ“ ç‚¹å‡»æˆåŠŸ")
            return True
            
        except Exception as e:
            print(f"   âŒ ç‚¹å‡»å¤±è´¥: {str(e)[:60]}")
            return False
    
    async def _analyze_after_click(self, source_item: Dict) -> None:
        """åˆ†æç‚¹å‡»åçš„é¡µé¢/å¼¹çª—"""
        page = self.browser_manager.page
        current_url = page.url
        url_key = self._normalize_url(current_url)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¼¹çª—/æ¨¡æ€æ¡†
        has_modal = await self._check_for_modal()
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°é¡µé¢
        is_new_page = url_key not in self.visited_urls
        if is_new_page:
            self.visited_urls.add(url_key)
        
        print(f"   ğŸ“„ å½“å‰çŠ¶æ€: {'å¼¹çª—' if has_modal else 'é¡µé¢'} - {current_url[:60]}...")
        
        # æˆªå›¾åˆ†æ
        screenshot = await self.browser_manager.screenshot()
        page_info = await self.page_analyzer.analyze_page(screenshot)
        
        page_type_str = page_info.get("page_type", "unknown")
        page_desc = page_info.get("page_description", "æœªçŸ¥")
        print(f"   ç±»å‹: {page_type_str}")
        print(f"   æè¿°: {page_desc}")
        
        # ä¿å­˜é¡µé¢/å¼¹çª—ä¿¡æ¯
        title = await page.title()
        page_model = PageModel(
            site_id=self.current_site.id,
            url_pattern=url_key + ("#modal" if has_modal else ""),
            title_pattern=title,
            page_type=PageType(page_type_str) if page_type_str in [e.value for e in PageType] else PageType.UNKNOWN,
            semantic_description=page_desc,
            key_features=json.dumps(page_info.get("key_features", []), ensure_ascii=False),
            sample_url=current_url,
            visit_count=1
        )
        page_model = self.db.save_page(page_model)
        
        # ä¿å­˜æˆªå›¾
        screenshot_path = os.path.join(
            self.config.exploration.screenshot_dir,
            f"{self.session_id}_{page_model.id}.png"
        )
        with open(screenshot_path, "wb") as f:
            f.write(screenshot)
        
        # è®°å½•æ“ä½œ
        action_type = ActionType.CLICK
        action = Action(
            site_id=self.current_site.id,
            source_page_id=source_item["source_page_id"],
            element_id=source_item["element_id"],
            action_type=action_type,
            target_page_id=page_model.id,
            notes=f"{source_item['item_type'].upper()}: {source_item['name']} ({source_item['crud_type']})"
        )
        self.db.save_action(action)
        
        # è®°å½•æ¢ç´¢æ—¥å¿—
        self.db.save_exploration_log(ExplorationLog(
            site_id=self.current_site.id,
            session_id=self.session_id,
            page_id=page_model.id,
            action_taken=f"{source_item['item_type'].upper()}: {source_item['name']}",
            result=f"{'å¼¹çª—' if has_modal else 'é¡µé¢'}: {title}",
            screenshot_path=screenshot_path
        ))
        
        # åˆ†ææ–°é¡µé¢/å¼¹çª—ä¸­çš„å…ƒç´ 
        if is_new_page or has_modal:
            print("   ğŸ·ï¸ åˆ†æé¡µé¢å…ƒç´ ...")
            tagged_screenshot, tag_to_xpath = await self.page_tagger.tag_page(page)
            
            if tagged_screenshot and tag_to_xpath:
                elements_info = await self.page_analyzer.analyze_elements(
                    tagged_screenshot,
                    page_desc
                )
                
                # æ”¶é›†æ–°çš„é¡¹ç›®
                new_items = 0
                for elem_info in elements_info:
                    tag_id = elem_info.get("tag_id")
                    if tag_id is None:
                        continue
                    
                    semantic_name = elem_info.get("semantic_name", "")
                    is_nav = elem_info.get("is_nav_menu", False)
                    is_crud = elem_info.get("is_crud_action", False)
                    crud_type = elem_info.get("crud_type", "none")
                    priority = elem_info.get("explore_priority", 5)
                    xpath = tag_to_xpath.get(tag_id)
                    
                    # ä¿å­˜å…ƒç´ 
                    elem_type_str = elem_info.get("element_type", "other")
                    element = Element(
                        page_id=page_model.id,
                        element_type=ElementType(elem_type_str) if elem_type_str in [e.value for e in ElementType] else ElementType.OTHER,
                        semantic_name=semantic_name,
                        semantic_description=elem_info.get("action_suggestion", ""),
                        text_content=elem_info.get("text_or_hint", ""),
                        importance=elem_info.get("importance", 5),
                        css_selector_hint=str(xpath) if xpath else ""
                    )
                    element = self.db.save_element(element)
                    
                    # å¦‚æœæ˜¯æ–°çš„é¡¹ç›®ï¼ŒåŠ å…¥å¾…æ¢ç´¢åˆ—è¡¨
                    item_key = f"{page_model.id}:{semantic_name}"
                    should_explore = (is_nav or is_crud or priority >= 7) and xpath and item_key not in self.visited_items
                    
                    if should_explore:
                        # æ£€æŸ¥æ˜¯å¦å·²åœ¨å¾…æ¢ç´¢åˆ—è¡¨ä¸­
                        existing = any(n["name"] == semantic_name and n["source_page_id"] == page_model.id 
                                       for n in self.pending_items)
                        if not existing:
                            item_type = "crud" if is_crud else ("nav" if is_nav else "action")
                            self.pending_items.append({
                                "name": semantic_name,
                                "xpath": xpath,
                                "priority": priority,
                                "element_id": element.id,
                                "source_page_id": page_model.id,
                                "source_url": current_url,
                                "item_type": item_type,
                                "crud_type": crud_type,
                                "text": elem_info.get("text_or_hint", "")
                            })
                            new_items += 1
                
                if new_items > 0:
                    print(f"   ğŸ“Œ å‘ç° {new_items} ä¸ªæ–°é¡¹ç›®")
                    # é‡æ–°æ’åº
                    self.pending_items.sort(key=lambda x: x["priority"], reverse=True)
            
            # æ¸…ç†æ ‡ç­¾
            await self.page_tagger.cleanup(page)
        
        # å¦‚æœæ˜¯å¼¹çª—ï¼Œå…³é—­å®ƒ
        if has_modal:
            await self._close_modal()
    
    async def _check_for_modal(self) -> bool:
        """æ£€æŸ¥é¡µé¢ä¸Šæ˜¯å¦æœ‰å¼¹çª—/æ¨¡æ€æ¡†"""
        page = self.browser_manager.page
        
        # å¸¸è§çš„å¼¹çª—é€‰æ‹©å™¨
        modal_selectors = [
            ".ant-modal",
            ".el-dialog",
            ".modal",
            "[role='dialog']",
            ".t-dialog",
            ".arco-modal"
        ]
        
        for selector in modal_selectors:
            try:
                elem = page.locator(selector).first
                if await elem.is_visible(timeout=1000):
                    return True
            except Exception:
                continue
        
        return False
    
    async def _close_modal(self) -> None:
        """å…³é—­å¼¹çª—"""
        page = self.browser_manager.page
        
        # å°è¯•ç‚¹å‡»å…³é—­æŒ‰é’®
        close_selectors = [
            ".ant-modal-close",
            ".el-dialog__close",
            ".modal-close",
            "[aria-label='Close']",
            ".t-dialog__close",
            "button:has-text('å–æ¶ˆ')",
            "button:has-text('å…³é—­')"
        ]
        
        for selector in close_selectors:
            try:
                elem = page.locator(selector).first
                if await elem.is_visible(timeout=1000):
                    await elem.click()
                    print("   âœ“ å…³é—­å¼¹çª—")
                    await asyncio.sleep(0.5)
                    return
            except Exception:
                continue
        
        # å¦‚æœæ‰¾ä¸åˆ°å…³é—­æŒ‰é’®ï¼ŒæŒ‰ ESC
        try:
            await page.keyboard.press("Escape")
            print("   âœ“ ESC å…³é—­å¼¹çª—")
        except Exception:
            pass
    
    def _normalize_url(self, url: str) -> str:
        """æ ‡å‡†åŒ– URLï¼ˆä¿ç•™ hash è·¯ç”±ï¼Œå»é™¤æŸ¥è¯¢å‚æ•°ï¼‰"""
        parsed = urlparse(url)
        # å¯¹äº SPA åº”ç”¨ï¼Œä¿ç•™ fragmentï¼ˆhashï¼‰
        if parsed.fragment:
            return f"{parsed.scheme}://{parsed.netloc}{parsed.path}#{parsed.fragment.split('?')[0]}"
        return f"{parsed.scheme}://{parsed.netloc}{parsed.path}"


class MemoryBasedPlanner:
    """åŸºäºè®°å¿†çš„ä»»åŠ¡è§„åˆ’å™¨"""
    
    PLAN_PROMPT = """ä½ æ˜¯ä¸€ä¸ªç½‘ç«™æ“ä½œä¸“å®¶ã€‚æ ¹æ®ç”¨æˆ·çš„ä»»åŠ¡å’Œç½‘ç«™è®°å¿†ï¼Œè§„åˆ’æ“ä½œæ­¥éª¤ã€‚

## ç½‘ç«™ä¿¡æ¯
åŸŸå: {domain}
å·²çŸ¥é¡µé¢:
{pages}

å·²çŸ¥æ“ä½œè·¯å¾„:
{actions}

å·²æœ‰ä»»åŠ¡è·¯å¾„:
{task_paths}

## ç”¨æˆ·ä»»åŠ¡
{task}

## å½“å‰é¡µé¢
URL: {current_url}
æè¿°: {current_page_desc}

è¯·åˆ†æä»»åŠ¡ï¼Œè¿”å› JSON æ ¼å¼çš„æ“ä½œè®¡åˆ’ï¼š
{{
    "can_plan": true/false,  // æ˜¯å¦èƒ½æ ¹æ®è®°å¿†è§„åˆ’
    "confidence": 0.0-1.0,   // ç½®ä¿¡åº¦
    "plan": [
        {{
            "step": 1,
            "action_type": "click/type/navigate",
            "target_description": "ç›®æ ‡å…ƒç´ æè¿°",
            "action_detail": "å…·ä½“æ“ä½œè¯´æ˜",
            "expected_result": "é¢„æœŸç»“æœ"
        }}
    ],
    "unknown_steps": ["éœ€è¦æ¢ç´¢æ‰èƒ½ç¡®å®šçš„æ­¥éª¤"]
}}

å¦‚æœè®°å¿†ä¸è¶³ä»¥å®Œæˆä»»åŠ¡ï¼Œè®¾ç½® can_plan=false å¹¶è¯´æ˜éœ€è¦æ¢ç´¢ä»€ä¹ˆã€‚"""

    def __init__(self, llm_client: VisionLLMClient, db: DatabaseInterface):
        self.llm = llm_client
        self.db = db
    
    async def plan_task(
        self,
        site: Site,
        task: str,
        current_url: str,
        current_page_desc: str
    ) -> Dict:
        """æ ¹æ®è®°å¿†è§„åˆ’ä»»åŠ¡"""
        # è·å–ç½‘ç«™è®°å¿†
        pages = self.db.get_pages_by_site(site.id)
        pages_desc = "\n".join([
            f"- [{p.page_type.value}] {p.semantic_description} ({p.url_pattern})"
            for p in pages[:20]
        ]) or "æš‚æ— è®°å½•"
        
        # è·å–å·²çŸ¥æ“ä½œ
        actions_desc_list = []
        for page in pages[:10]:
            actions = self.db.get_actions_from_page(page.id)
            for action in actions[:5]:
                actions_desc_list.append(
                    f"- {page.semantic_description} -> {action.notes}"
                )
        actions_desc = "\n".join(actions_desc_list) or "æš‚æ— è®°å½•"
        
        # è·å–å·²æœ‰ä»»åŠ¡è·¯å¾„
        task_paths = self.db.get_task_paths_by_site(site.id)
        paths_desc = "\n".join([
            f"- {tp.task_description}"
            for tp in task_paths[:10]
        ]) or "æš‚æ— è®°å½•"
        
        prompt = self.PLAN_PROMPT.format(
            domain=site.domain,
            pages=pages_desc,
            actions=actions_desc,
            task_paths=paths_desc,
            task=task,
            current_url=current_url,
            current_page_desc=current_page_desc
        )
        
        try:
            response = await self.llm.chat(prompt)
            
            if response:
                json_match = re.search(r'\{[\s\S]*\}', response)
                if json_match:
                    return json.loads(json_match.group())
        except json.JSONDecodeError:
            pass
        except Exception as e:
            print(f"è§„åˆ’ä»»åŠ¡å¤±è´¥: {e}")
        
        return {
            "can_plan": False,
            "confidence": 0.0,
            "plan": [],
            "unknown_steps": ["æ— æ³•è§£æè§„åˆ’ç»“æœ"]
        }
